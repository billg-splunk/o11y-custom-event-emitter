{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"overview/","text":"Custom Observability Event Emitter for AWS Codepipeline CI/CD \u00b6 Overview \u00b6 This AWS Lambda function is designed to ingest AWS Codepipeline Events published to an AWS SNS (Simple Notification Service) topic and POST them to Splunk Observability Cloud. The basic workflow includes these stages \u00b6 A connection is configured between a Github repository & AWS Codepipeline. When changes on a watched branch are committed to Github, AWS Codepipeline takes over to pull the source code. A notification of this event is published to the SNS Topic The Lambda function has a subscription to the notification topic and is invoked with the payload of the message as the function's input. The function creates a simple HTTP POST payload that's sent to the Observability Ingest API. The payload is designed to carry some details about the Codepipeline event that invoked the function. At each subsequent stage in the Codepipeline process, the same process repeats itself. Once these events arrive in Observability Cloud, they can be added as event overlays on various Charts and Dashboard elements, as well as represented as Table or Counter charts. The possibilities are endless Implementing The Workflow \u00b6 For the purposes of a proof-of-concept, it would be sufficient to have a simple pipeline that includes three stages to a complete CI/CD workflow: Source Build Deploy The most involved part of creating this POC is building a functional AWS CodePipeline. If you already have access to one, skip ahead to a future section.","title":"Overview"},{"location":"overview/#custom-observability-event-emitter-for-aws-codepipeline-cicd","text":"","title":"Custom Observability Event Emitter for AWS Codepipeline CI/CD"},{"location":"overview/#overview","text":"This AWS Lambda function is designed to ingest AWS Codepipeline Events published to an AWS SNS (Simple Notification Service) topic and POST them to Splunk Observability Cloud.","title":"Overview"},{"location":"overview/#the-basic-workflow-includes-these-stages","text":"A connection is configured between a Github repository & AWS Codepipeline. When changes on a watched branch are committed to Github, AWS Codepipeline takes over to pull the source code. A notification of this event is published to the SNS Topic The Lambda function has a subscription to the notification topic and is invoked with the payload of the message as the function's input. The function creates a simple HTTP POST payload that's sent to the Observability Ingest API. The payload is designed to carry some details about the Codepipeline event that invoked the function. At each subsequent stage in the Codepipeline process, the same process repeats itself. Once these events arrive in Observability Cloud, they can be added as event overlays on various Charts and Dashboard elements, as well as represented as Table or Counter charts. The possibilities are endless","title":"The basic workflow includes these stages"},{"location":"overview/#implementing-the-workflow","text":"For the purposes of a proof-of-concept, it would be sufficient to have a simple pipeline that includes three stages to a complete CI/CD workflow: Source Build Deploy The most involved part of creating this POC is building a functional AWS CodePipeline. If you already have access to one, skip ahead to a future section.","title":"Implementing The Workflow"},{"location":"pre-reqs/","text":"Pre-Requisites \u00b6 Install the AWS CLI & SAM CLI . Create an EC2 instance to run the Spring Boot application aws ec2 run-instances \\ --image-id ami-002068ed284fb165b \\ --count 1 \\ --instance-type t2.micro \\ --key-name <a valid AWS key pair to which you have access> \\ --security-group-ids <a security group with SSH and TCP 8080 open from any ip> \\ --associate-public-ip-address \\ --user-data $( curl https://raw.githubusercontent.com/tjohander-splunk/aws-one-liners/main/user-data-scripts/spring-boot-app-server.sh | base64 ) \\ --tag-specifications 'ResourceType=instance,Tags=[{Key=application,Value=Spring-Pet-Clinic}]' Fork and Clone the Spring Boot Pet Clinic App and supporting AWS CodeDeploy files","title":"Pre-Requisites"},{"location":"pre-reqs/#pre-requisites","text":"Install the AWS CLI & SAM CLI . Create an EC2 instance to run the Spring Boot application aws ec2 run-instances \\ --image-id ami-002068ed284fb165b \\ --count 1 \\ --instance-type t2.micro \\ --key-name <a valid AWS key pair to which you have access> \\ --security-group-ids <a security group with SSH and TCP 8080 open from any ip> \\ --associate-public-ip-address \\ --user-data $( curl https://raw.githubusercontent.com/tjohander-splunk/aws-one-liners/main/user-data-scripts/spring-boot-app-server.sh | base64 ) \\ --tag-specifications 'ResourceType=instance,Tags=[{Key=application,Value=Spring-Pet-Clinic}]' Fork and Clone the Spring Boot Pet Clinic App and supporting AWS CodeDeploy files","title":"Pre-Requisites"}]}