{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"execute-demo/","text":"This is where the fun starts \u00b6","title":"Execute the Demo"},{"location":"execute-demo/#this-is-where-the-fun-starts","text":"","title":"This is where the fun starts"},{"location":"overview/","text":"Custom Observability Event Emitter for AWS Codepipeline CI/CD \u00b6 Overview \u00b6 This Demo is intended to show the capabilities of Splunk Observability Cloud's custom event capabilities. It demonstrates how a popular Continuous Integration / Continuous Deployment (CI/CD) Workflow can be adapted to send valuable information into Observability Cloud to correlate application release events with specific infrastructure, application and business performance metrics. The Workflow \u00b6 The workflow in this demo involves a typical process by which software development teams create and maintain projects. Code is continually updated by developers using a central version control system (VCS). In this case a sample Github repository is used, but Bitbucket or AWS CodeCommit are alternatives that would also work. When the main branch is updated, AWS CodePipeline takes over to: Download the latest code. Run automated tests on the source code. Compile and build any supporting artifacts Deploy the finished artifacts into QA, staging or production runtime environments to deliver the value for which they were created. Each of these stages should be automated to allow software teams to focus on the quality of the code, not the mechanics of deploying and running it. This is the foundation of a modern DevOps paradigm. The challenges this process can present to many customers is how to correlate a CI/CD workflow (\"pipeline\") like this to environment health or business objectives. It's incredibly useful to be able to quickly and painlessly correlate software release events with other health metrics to quickly identify issues in a new release or impact on business objectives. This is where Splunk Observability's capabilities to accept custom events and overlay display them on other charts and dashboards is invaluable. This demo will walk you through exactly how to do that. Implementation Details \u00b6 The technical details of this demo features out-of-the-box capabilities in a Github & AWS-based workflow, although it could be adapted to use a different Version Control System (BitBucket, CodeCommit) or Continuous Delivery platform (Jenkins, Cloudbees, CircleCI). A connection is configured between a Github repository & AWS Codepipeline. When changes on a watched branch are committed to Github, AWS Codepipeline takes over to pull the source code. A notification of this event is published to the SNS Topic The Lambda function has a subscription to the notification topic and is invoked with the payload of the message as the function's input. The function creates a simple HTTP POST payload that's sent to the Observability Ingest API. The payload is designed to carry some details about the Codepipeline event that invoked the function. At each subsequent stage in the Codepipeline process, the same process repeats itself. Once these events arrive in Observability Cloud, they can be added as event overlays on various Charts and Dashboard elements, as well as represented as Table or Counter charts. The possibilities are endless","title":"Overview"},{"location":"overview/#custom-observability-event-emitter-for-aws-codepipeline-cicd","text":"","title":"Custom Observability Event Emitter for AWS Codepipeline CI/CD"},{"location":"overview/#overview","text":"This Demo is intended to show the capabilities of Splunk Observability Cloud's custom event capabilities. It demonstrates how a popular Continuous Integration / Continuous Deployment (CI/CD) Workflow can be adapted to send valuable information into Observability Cloud to correlate application release events with specific infrastructure, application and business performance metrics.","title":"Overview"},{"location":"overview/#the-workflow","text":"The workflow in this demo involves a typical process by which software development teams create and maintain projects. Code is continually updated by developers using a central version control system (VCS). In this case a sample Github repository is used, but Bitbucket or AWS CodeCommit are alternatives that would also work. When the main branch is updated, AWS CodePipeline takes over to: Download the latest code. Run automated tests on the source code. Compile and build any supporting artifacts Deploy the finished artifacts into QA, staging or production runtime environments to deliver the value for which they were created. Each of these stages should be automated to allow software teams to focus on the quality of the code, not the mechanics of deploying and running it. This is the foundation of a modern DevOps paradigm. The challenges this process can present to many customers is how to correlate a CI/CD workflow (\"pipeline\") like this to environment health or business objectives. It's incredibly useful to be able to quickly and painlessly correlate software release events with other health metrics to quickly identify issues in a new release or impact on business objectives. This is where Splunk Observability's capabilities to accept custom events and overlay display them on other charts and dashboards is invaluable. This demo will walk you through exactly how to do that.","title":"The Workflow"},{"location":"overview/#implementation-details","text":"The technical details of this demo features out-of-the-box capabilities in a Github & AWS-based workflow, although it could be adapted to use a different Version Control System (BitBucket, CodeCommit) or Continuous Delivery platform (Jenkins, Cloudbees, CircleCI). A connection is configured between a Github repository & AWS Codepipeline. When changes on a watched branch are committed to Github, AWS Codepipeline takes over to pull the source code. A notification of this event is published to the SNS Topic The Lambda function has a subscription to the notification topic and is invoked with the payload of the message as the function's input. The function creates a simple HTTP POST payload that's sent to the Observability Ingest API. The payload is designed to carry some details about the Codepipeline event that invoked the function. At each subsequent stage in the Codepipeline process, the same process repeats itself. Once these events arrive in Observability Cloud, they can be added as event overlays on various Charts and Dashboard elements, as well as represented as Table or Counter charts. The possibilities are endless","title":"Implementation Details"},{"location":"pre-reqs/","text":"Pre-Requisites \u00b6 AWS & SAM CLI \u00b6 Install the AWS CLI & SAM CLI . Configure the AWS CLI with the credentials for an AWS account to which you have access: aws --configure Details on installation and configuration for the AWS CLI can be found here . Similar details for the SAM CLI can be found here . Create a Connection Between Github and AWS \u00b6 This step requires some manual intervention to approve a connection once you create it with the following command: aws codestar-connections create-connection \\ --provider-type Github \\ --connection-name <some-artbitrary-value> When this is done, the connection is in a pending state and there is another step. Log into the AWS console and update the connection state from \"Pending\" to \"Active\". Details are here . You must use the console to update a pending connection. You cannot update a pending connection using the AWS CLI. Note the ARN of this resource once it's created. You'll need it in a subsequent step. This connection is used in building the CI/CD pipeline but it's an account-level object and you can re-use this for anything else in AWS you'd like. It's like a parting gift of this demo. Generate or Locate an EC2 SSH Keypair \u00b6 Create an SSH KeyPair to connect to an EC2 Instance if you don't already have one. aws ec2 create-key-pair \\ --key-name my-key-pair \\ --key-type rsa \\ --query \"KeyMaterial\" \\ --output text > my-key-pair.pem Whether you created one or have a pre-existing key you use to connect to EC2 instances, note the key-name of the key. You'll need to initialize the Cloudformation stack. Find a Suitable Observability Cloud Environment \u00b6 Locate an Observability Cloud environment to which you will deploy custom CI/CD events. Note the realm and Access Token . Fork and Clone the Sample Application \u00b6 Fork and clone the repository at https://github.com/tjohander-splunk/spring-petclinic . If you are familiar with Git, this should be quite easy. If you've never forked or cloned a repository, detailed instructions can be found here git clone <your-fork-repo-url> For the purposes of this demo we will use this Java/Spring Boot application. The actual application code is unchanged from the classic Spring authored application, but does include some additional files that AWS CodePipeline needs for this CI/CD workflow to execute properly. Note your Github org and repository values. They will be needed in a subsequent step. Create an instance role for the EC2 app server to allow it to receive CodeDeploy deployments. Create an EC2 instance to run the Spring Boot application aws ec2 run-instances \\ --image-id ami-002068ed284fb165b \\ --count 1 \\ --instance-type t2.micro \\ --key-name <a valid AWS key pair to which you have access> \\ --security-group-ids <a security group with SSH and TCP 8080 open from any ip> \\ --associate-public-ip-address \\ --user-data $( curl https://raw.githubusercontent.com/tjohander-splunk/aws-one-liners/main/user-data-scripts/spring-boot-app-server.sh | base64 ) \\ --tag-specifications 'ResourceType=instance,Tags=[{Key=application,Value=Spring-Pet-Clinic}]' Fork and Clone the Spring Boot Pet Clinic App and supporting AWS CodeDeploy files","title":"Pre-Requisites"},{"location":"pre-reqs/#pre-requisites","text":"","title":"Pre-Requisites"},{"location":"pre-reqs/#aws-sam-cli","text":"Install the AWS CLI & SAM CLI . Configure the AWS CLI with the credentials for an AWS account to which you have access: aws --configure Details on installation and configuration for the AWS CLI can be found here . Similar details for the SAM CLI can be found here .","title":"AWS &amp; SAM CLI"},{"location":"pre-reqs/#create-a-connection-between-github-and-aws","text":"This step requires some manual intervention to approve a connection once you create it with the following command: aws codestar-connections create-connection \\ --provider-type Github \\ --connection-name <some-artbitrary-value> When this is done, the connection is in a pending state and there is another step. Log into the AWS console and update the connection state from \"Pending\" to \"Active\". Details are here . You must use the console to update a pending connection. You cannot update a pending connection using the AWS CLI. Note the ARN of this resource once it's created. You'll need it in a subsequent step. This connection is used in building the CI/CD pipeline but it's an account-level object and you can re-use this for anything else in AWS you'd like. It's like a parting gift of this demo.","title":"Create a Connection Between Github and AWS"},{"location":"pre-reqs/#generate-or-locate-an-ec2-ssh-keypair","text":"Create an SSH KeyPair to connect to an EC2 Instance if you don't already have one. aws ec2 create-key-pair \\ --key-name my-key-pair \\ --key-type rsa \\ --query \"KeyMaterial\" \\ --output text > my-key-pair.pem Whether you created one or have a pre-existing key you use to connect to EC2 instances, note the key-name of the key. You'll need to initialize the Cloudformation stack.","title":"Generate or Locate an EC2 SSH Keypair"},{"location":"pre-reqs/#find-a-suitable-observability-cloud-environment","text":"Locate an Observability Cloud environment to which you will deploy custom CI/CD events. Note the realm and Access Token .","title":"Find a Suitable Observability Cloud Environment"},{"location":"pre-reqs/#fork-and-clone-the-sample-application","text":"Fork and clone the repository at https://github.com/tjohander-splunk/spring-petclinic . If you are familiar with Git, this should be quite easy. If you've never forked or cloned a repository, detailed instructions can be found here git clone <your-fork-repo-url> For the purposes of this demo we will use this Java/Spring Boot application. The actual application code is unchanged from the classic Spring authored application, but does include some additional files that AWS CodePipeline needs for this CI/CD workflow to execute properly. Note your Github org and repository values. They will be needed in a subsequent step. Create an instance role for the EC2 app server to allow it to receive CodeDeploy deployments. Create an EC2 instance to run the Spring Boot application aws ec2 run-instances \\ --image-id ami-002068ed284fb165b \\ --count 1 \\ --instance-type t2.micro \\ --key-name <a valid AWS key pair to which you have access> \\ --security-group-ids <a security group with SSH and TCP 8080 open from any ip> \\ --associate-public-ip-address \\ --user-data $( curl https://raw.githubusercontent.com/tjohander-splunk/aws-one-liners/main/user-data-scripts/spring-boot-app-server.sh | base64 ) \\ --tag-specifications 'ResourceType=instance,Tags=[{Key=application,Value=Spring-Pet-Clinic}]' Fork and Clone the Spring Boot Pet Clinic App and supporting AWS CodeDeploy files","title":"Fork and Clone the Sample Application"},{"location":"provisioning-automated/","text":"Generate All AWS Resources to Run The Demo \u00b6 This step will use the power of the SAM and Cloudformation to automate the construction of all these resources. Cloudformation is a very powerful Infrastrcuture-as-Code (IaC) tool. It's recommended to use this process to build all the AWS resources. Manually provisioning everything is time-consuming and error-prone. Let's get started! Step 1: Download the contents of this repository \u00b6 git clone https://github.com/tjohander-splunk/o11y-custom-event-emitter.git && cd o11y-custom-event-emitter Step 2: Build and Deploy the All Required AWS Resources \u00b6 The SAM CLI is an extension to the AWS CLI and can process various files needed to deploy a serverless function and any related AWS resources. The template.yaml file describes all the resources we will need for this demo. Step 2a: Initialize The Project \u00b6 Enter this command to initialize the project app code and configuration: sam build Step 2b: Provide values for each parameter required to process the resources \u00b6 Enter this command to start the deploy phase. The --guided switch will take you through a series of questions asking for values to assign the parameters contained in the template. sam deploy --guided This command will walk you through setting values for the required parameter values for the various AWS resources. If there are defaults found in the config file, you can hit enter to use them. Details on how to answer each question are provided in the comments above each question # Pick anything you want here Stack Name [ sam-app-observability-demo ] : # The region you specificy in your AWS CLI Config AWS Region [ us-east-2 ] : # The o11y realm to send events Parameter Realm [ us0 ] : # an access token for this o11y environment Parameter AccessToken: # the SSH keypair you own to connect to EC2 instances Parameter KeyName [ tj-devlab-key-pair-001 ] : # default is fine Parameter InstanceType [ t2.small ] : # if you want to lock down SSH to single source IP Parameter SSHLocation [ 0 .0.0.0/0 ] : # the repo of the sample project Parameter GitHubRepo [ tjohander-splunk/spring-petclinic ] : # the Github/AWS Connection ARN Parameter GitHubConnectionARN [ arn:aws:codestar-connections:us-east-2:455790677231:connection/aaeb5a4f-b91f-4655-a234-e3ff4c8d1176 ] : # An arbitrary prefix to all custom events. Please add something to make here your events easy to find. Parameter EventType [ TSJ CI-CD Pipeline Event ] : #Shows you resources changes to be deployed and require a 'Y' to initiate deploy Confirm changes before deploy [ Y/n ] : #SAM needs permission to be able to create roles to connect to the resources in your template Allow SAM CLI IAM role creation [ Y/n ] : #Preserves the state of previously provisioned resources when an operation fails Disable rollback [ Y/n ] : <default is fine> Save arguments to configuration file [ Y/n ] : <default is fine> SAM configuration file [ samconfig.toml ] : <default is fine> SAM configuration environment [ default ] : <default is fine> Once a changeSet is created, go ahead and run it. There will be quite a bit of information output to your terminal, go ahead and follow the prompts to deploy all the AWS resources. If issues pop up, do your best to remediate or hit me up on Slack (\"Tom Johander\") or email (\"tjohander@splunk.com\") Step 4: Monitor the Pipeline \u00b6 As the process goes down, the initial run of the pipeline will kick off. It's all automatic and you can watch the pipeline run on the AWS Console. Go to the CodePipeline \"Pipelines\" UI and click the name of the pipeline that's created. As each step and each stage start, succeed or fail, a notification is sent to the Lambda function defined in the app.js file in this repo. This is what's sending pipeline events to Observability cloud...so let's go take a look! Note: The first time the pipeline runs, it's takes about 6 to 7 minutes to complete. This is due to all the dependencies of the sample app needing to be downloaded. There is some caching built into the pipeline, so subsequent runs of the pipeline should take about 45 seconds to finish. Step 5: Ensure some events make it into O11y \u00b6 Jump into your O11y environment and open a dashboard. Create an Event Feed Chart \u00b6 Open the \"Event Feed\" and select the \"Find Events\" radio button Search with the name prefix you set during the sam deploy --guided questionnaire. Select \"Add Single Chart\" Overlay Events on a different chart \u00b6 In the top bar of the dashboard, find and select your custom event type in the \"Event Overlay\" field. This will overlay custom events on the X-axis of any time chart that's appropriate. Step 6: Ready for Demo \u00b6 If everything looks good at this point, you should be ready to deliver a great demo","title":"Provision AWS Resources via Automation (Recommended)"},{"location":"provisioning-automated/#generate-all-aws-resources-to-run-the-demo","text":"This step will use the power of the SAM and Cloudformation to automate the construction of all these resources. Cloudformation is a very powerful Infrastrcuture-as-Code (IaC) tool. It's recommended to use this process to build all the AWS resources. Manually provisioning everything is time-consuming and error-prone. Let's get started!","title":"Generate All AWS Resources to Run The Demo"},{"location":"provisioning-automated/#step-1-download-the-contents-of-this-repository","text":"git clone https://github.com/tjohander-splunk/o11y-custom-event-emitter.git && cd o11y-custom-event-emitter","title":"Step 1: Download the contents of this repository"},{"location":"provisioning-automated/#step-2-build-and-deploy-the-all-required-aws-resources","text":"The SAM CLI is an extension to the AWS CLI and can process various files needed to deploy a serverless function and any related AWS resources. The template.yaml file describes all the resources we will need for this demo.","title":"Step 2: Build and Deploy the All Required AWS Resources"},{"location":"provisioning-automated/#step-2a-initialize-the-project","text":"Enter this command to initialize the project app code and configuration: sam build","title":"Step 2a: Initialize The Project"},{"location":"provisioning-automated/#step-2b-provide-values-for-each-parameter-required-to-process-the-resources","text":"Enter this command to start the deploy phase. The --guided switch will take you through a series of questions asking for values to assign the parameters contained in the template. sam deploy --guided This command will walk you through setting values for the required parameter values for the various AWS resources. If there are defaults found in the config file, you can hit enter to use them. Details on how to answer each question are provided in the comments above each question # Pick anything you want here Stack Name [ sam-app-observability-demo ] : # The region you specificy in your AWS CLI Config AWS Region [ us-east-2 ] : # The o11y realm to send events Parameter Realm [ us0 ] : # an access token for this o11y environment Parameter AccessToken: # the SSH keypair you own to connect to EC2 instances Parameter KeyName [ tj-devlab-key-pair-001 ] : # default is fine Parameter InstanceType [ t2.small ] : # if you want to lock down SSH to single source IP Parameter SSHLocation [ 0 .0.0.0/0 ] : # the repo of the sample project Parameter GitHubRepo [ tjohander-splunk/spring-petclinic ] : # the Github/AWS Connection ARN Parameter GitHubConnectionARN [ arn:aws:codestar-connections:us-east-2:455790677231:connection/aaeb5a4f-b91f-4655-a234-e3ff4c8d1176 ] : # An arbitrary prefix to all custom events. Please add something to make here your events easy to find. Parameter EventType [ TSJ CI-CD Pipeline Event ] : #Shows you resources changes to be deployed and require a 'Y' to initiate deploy Confirm changes before deploy [ Y/n ] : #SAM needs permission to be able to create roles to connect to the resources in your template Allow SAM CLI IAM role creation [ Y/n ] : #Preserves the state of previously provisioned resources when an operation fails Disable rollback [ Y/n ] : <default is fine> Save arguments to configuration file [ Y/n ] : <default is fine> SAM configuration file [ samconfig.toml ] : <default is fine> SAM configuration environment [ default ] : <default is fine> Once a changeSet is created, go ahead and run it. There will be quite a bit of information output to your terminal, go ahead and follow the prompts to deploy all the AWS resources. If issues pop up, do your best to remediate or hit me up on Slack (\"Tom Johander\") or email (\"tjohander@splunk.com\")","title":"Step 2b: Provide values for each parameter required to process the resources"},{"location":"provisioning-automated/#step-4-monitor-the-pipeline","text":"As the process goes down, the initial run of the pipeline will kick off. It's all automatic and you can watch the pipeline run on the AWS Console. Go to the CodePipeline \"Pipelines\" UI and click the name of the pipeline that's created. As each step and each stage start, succeed or fail, a notification is sent to the Lambda function defined in the app.js file in this repo. This is what's sending pipeline events to Observability cloud...so let's go take a look! Note: The first time the pipeline runs, it's takes about 6 to 7 minutes to complete. This is due to all the dependencies of the sample app needing to be downloaded. There is some caching built into the pipeline, so subsequent runs of the pipeline should take about 45 seconds to finish.","title":"Step 4: Monitor the Pipeline"},{"location":"provisioning-automated/#step-5-ensure-some-events-make-it-into-o11y","text":"Jump into your O11y environment and open a dashboard.","title":"Step 5: Ensure some events make it into O11y"},{"location":"provisioning-automated/#create-an-event-feed-chart","text":"Open the \"Event Feed\" and select the \"Find Events\" radio button Search with the name prefix you set during the sam deploy --guided questionnaire. Select \"Add Single Chart\"","title":"Create an Event Feed Chart"},{"location":"provisioning-automated/#overlay-events-on-a-different-chart","text":"In the top bar of the dashboard, find and select your custom event type in the \"Event Overlay\" field. This will overlay custom events on the X-axis of any time chart that's appropriate.","title":"Overlay Events on a different chart"},{"location":"provisioning-automated/#step-6-ready-for-demo","text":"If everything looks good at this point, you should be ready to deliver a great demo","title":"Step 6: Ready for Demo"},{"location":"provisioning-manual/","text":"Pre-Requisites \u00b6 Install the AWS CLI & SAM CLI . Create an EC2 instance to run the Spring Boot application aws ec2 run-instances \\ --image-id ami-002068ed284fb165b \\ --count 1 \\ --instance-type t2.micro \\ --key-name <a valid AWS key pair to which you have access> \\ --security-group-ids <a security group with SSH and TCP 8080 open from any ip> \\ --associate-public-ip-address \\ --user-data $( curl https://raw.githubusercontent.com/tjohander-splunk/aws-one-liners/main/user-data-scripts/spring-boot-app-server.sh | base64 ) \\ --tag-specifications 'ResourceType=instance,Tags=[{Key=application,Value=Spring-Pet-Clinic}]' Fork and Clone the Spring Boot Pet Clinic App and supporting AWS CodeDeploy files Step 1: Create a New Pipeline \u00b6 In the AWS Console, head to the CodePipeline service and click \"Create Pipeline\". The role name that AWS creates on your behalf will include the name you give to the pipeline. Click \"Next\" Step 2: Connect Github to your AWS Account \u00b6 This only needs to be done once. The result is an AWS resource that is not directly tied to this demo. Select Github (Version 2) as your Source Provider Click \"Connect to Github\" You'll be prompted to create a Connection Name: Then you'll be asked to sign in to Github: The Github Connection should be created and its ARN added to the Source configuration. Complete the fields for the Github repository and branch you want this pipeline to watch: 3: Setup the Pipeline's \"Build\" Stage \u00b6 This stage will receive the application source code and execute the steps needed to build the application: download dependencies, compile the source code, run any unit & integration tests and any other tasks needed to convert the source code into a runnable application that can be deployed to an application server or other runtime environment. * For the Build Provider, select \"AWS CodeBuild\" and select the region in which you want this build to be executed * Click \"Create Build Project\". You'll be presented with a popup to configure a new Build project. Apply settings similar to the following: Note on Cache Settings \u00b6 This may not be necessary if you choose to build and deploy an application other than Spring Pet Clinic, a Spring Boot / Java project with many dependencies. Each time the build process is executed, the build environment re-downloads all these dependencies. This can take over 5 minutes and can get tedious while iterating or demoing the solution. The screenshots reflect the necessary configuration to cache these dependencies in an S3 bucket, thus greatly speeding up the time needed to build this particular application. * Once a build project is either created or an existing build project is selected, the Build stage configuration should look similar to this: Step 4: Setup the Pipeline's \"Deploy\" Stage \u00b6 This step will take the application artifact created in the previous step and deploy it to an EC2 instance. In order to complete the configuration for this stage, we must first create a CodeDeploy Application resource and a Deployment Group for that application. In AWS CodeDeploy, go the \"Applications\" interface Select \"Create New Application\" Fill in the fields to create an application: Create a Deployment Group as the deployment target. In this case, we'll deploy the application executable to any EC2 instances that match the tags we specify in the Environment Configuration section. You'll know you've got things lined up correctly when the UI reports that it matched an instance: Once this is all created, the fields in the Deploy stage should auto-populate with valid options for each field similar to the screenshot below: After the Source, Build and Deploy stages are complete you should be presented with a final review and an option to \"Create Pipeline\": Create the pipeline and move on to the next step. Step 5: Create SNS Topic \u00b6 This step will create the SNS (Simple Notification Service) topic that to which the Lambda function will subscribe. Head over to the AWS SNS UI, select \"Topics\" and click the \"Create New Topic\" button. Create a topic with these values: Note the ARN of this topic. It will be needed in the next step. Step 7: Update the Lambda definition to trigger on receipt of a notification on the SNS topic \u00b6 In the template.yaml file located in the root of this project, fill in the topic ARN here: Resources : O11yEventEmitterFunction : Type : AWS::Serverless::Function # More info about Function Resource: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#awsserverlessfunction Properties : CodeUri : o11y-event-emitter/ Handler : app.lambdaHandler Runtime : nodejs12.x Architectures : - x86_64 Events : HelloWorld : Type : SNS Properties : Topic : <insert-arn-here> Step 8: Create Notification Rule For The CodePipeline \u00b6 Now that we have a topic created, configure the pipeline to send notifications of various events to the SNS topic. In the main pipeline UI, select \"Notifiy\", then \"Create Notification Rule\". Fill on values to reflect a configuration like this: The SNS topic should auto-populate as an option in the \"Choose target\" field. That's it! The pipeline is complete. Now we will need to deploy our Lambda function and then test everything out by pushing a small change to the application to kick off the pipeline. Step 9: Deploy the Lambda function with the SAM CLI \u00b6 From a terminal instance with the SAM CLI installed and configured, execute the following commands: sam build sam deploy --guided --parameter-overrides Realm = <o11y cloud realm> AccessToken = <o11y cloud access token> Step 10: Push a small change to the source application code to trigger a pipeline execution \u00b6 Any change to the source code in the repository will trigger a change. You can even just edit the README.md file in the root of the project. It's nice to show an acutal change to the application, so maybe editing the welcome message that's presented to users on the landing page of the web app is something we want to do. It's easy to make the change, simply open the file located at src/main/resources/messages/messages.properties and edit the welcome message. This text is immediately visible on the landing page and demonstrates that the application code has indeed changed and been deployed to a functional runtime environment. Once you edit the file execute standard git commands to push your change to Github: git add . git commit -m \"Updated the welcome message\" git push Step 11: Validate you have custom events in O11y Cloud \u00b6 Once the pipeline completes successfully, you should be able to search O11y for your custom events. To do so, open up a Dashboard and look for matching events in the Event Overlay field or in the Event Finder panel. Once your events are located you can set them as overlays, create a Table chart showing a list of events, etc...","title":"Provision AWS Resources (Not Recommended)"},{"location":"provisioning-manual/#pre-requisites","text":"Install the AWS CLI & SAM CLI . Create an EC2 instance to run the Spring Boot application aws ec2 run-instances \\ --image-id ami-002068ed284fb165b \\ --count 1 \\ --instance-type t2.micro \\ --key-name <a valid AWS key pair to which you have access> \\ --security-group-ids <a security group with SSH and TCP 8080 open from any ip> \\ --associate-public-ip-address \\ --user-data $( curl https://raw.githubusercontent.com/tjohander-splunk/aws-one-liners/main/user-data-scripts/spring-boot-app-server.sh | base64 ) \\ --tag-specifications 'ResourceType=instance,Tags=[{Key=application,Value=Spring-Pet-Clinic}]' Fork and Clone the Spring Boot Pet Clinic App and supporting AWS CodeDeploy files","title":"Pre-Requisites"},{"location":"provisioning-manual/#step-1-create-a-new-pipeline","text":"In the AWS Console, head to the CodePipeline service and click \"Create Pipeline\". The role name that AWS creates on your behalf will include the name you give to the pipeline. Click \"Next\"","title":"Step 1: Create a New Pipeline"},{"location":"provisioning-manual/#step-2-connect-github-to-your-aws-account","text":"This only needs to be done once. The result is an AWS resource that is not directly tied to this demo. Select Github (Version 2) as your Source Provider Click \"Connect to Github\" You'll be prompted to create a Connection Name: Then you'll be asked to sign in to Github: The Github Connection should be created and its ARN added to the Source configuration. Complete the fields for the Github repository and branch you want this pipeline to watch:","title":"Step 2: Connect Github to your AWS Account"},{"location":"provisioning-manual/#3-setup-the-pipelines-build-stage","text":"This stage will receive the application source code and execute the steps needed to build the application: download dependencies, compile the source code, run any unit & integration tests and any other tasks needed to convert the source code into a runnable application that can be deployed to an application server or other runtime environment. * For the Build Provider, select \"AWS CodeBuild\" and select the region in which you want this build to be executed * Click \"Create Build Project\". You'll be presented with a popup to configure a new Build project. Apply settings similar to the following:","title":"3: Setup the Pipeline's \"Build\" Stage"},{"location":"provisioning-manual/#note-on-cache-settings","text":"This may not be necessary if you choose to build and deploy an application other than Spring Pet Clinic, a Spring Boot / Java project with many dependencies. Each time the build process is executed, the build environment re-downloads all these dependencies. This can take over 5 minutes and can get tedious while iterating or demoing the solution. The screenshots reflect the necessary configuration to cache these dependencies in an S3 bucket, thus greatly speeding up the time needed to build this particular application. * Once a build project is either created or an existing build project is selected, the Build stage configuration should look similar to this:","title":"Note on Cache Settings"},{"location":"provisioning-manual/#step-4-setup-the-pipelines-deploy-stage","text":"This step will take the application artifact created in the previous step and deploy it to an EC2 instance. In order to complete the configuration for this stage, we must first create a CodeDeploy Application resource and a Deployment Group for that application. In AWS CodeDeploy, go the \"Applications\" interface Select \"Create New Application\" Fill in the fields to create an application: Create a Deployment Group as the deployment target. In this case, we'll deploy the application executable to any EC2 instances that match the tags we specify in the Environment Configuration section. You'll know you've got things lined up correctly when the UI reports that it matched an instance: Once this is all created, the fields in the Deploy stage should auto-populate with valid options for each field similar to the screenshot below: After the Source, Build and Deploy stages are complete you should be presented with a final review and an option to \"Create Pipeline\": Create the pipeline and move on to the next step.","title":"Step 4: Setup the Pipeline's \"Deploy\" Stage"},{"location":"provisioning-manual/#step-5-create-sns-topic","text":"This step will create the SNS (Simple Notification Service) topic that to which the Lambda function will subscribe. Head over to the AWS SNS UI, select \"Topics\" and click the \"Create New Topic\" button. Create a topic with these values: Note the ARN of this topic. It will be needed in the next step.","title":"Step 5: Create SNS Topic"},{"location":"provisioning-manual/#step-7-update-the-lambda-definition-to-trigger-on-receipt-of-a-notification-on-the-sns-topic","text":"In the template.yaml file located in the root of this project, fill in the topic ARN here: Resources : O11yEventEmitterFunction : Type : AWS::Serverless::Function # More info about Function Resource: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#awsserverlessfunction Properties : CodeUri : o11y-event-emitter/ Handler : app.lambdaHandler Runtime : nodejs12.x Architectures : - x86_64 Events : HelloWorld : Type : SNS Properties : Topic : <insert-arn-here>","title":"Step 7: Update the Lambda definition to trigger on receipt of a notification on the SNS topic"},{"location":"provisioning-manual/#step-8-create-notification-rule-for-the-codepipeline","text":"Now that we have a topic created, configure the pipeline to send notifications of various events to the SNS topic. In the main pipeline UI, select \"Notifiy\", then \"Create Notification Rule\". Fill on values to reflect a configuration like this: The SNS topic should auto-populate as an option in the \"Choose target\" field. That's it! The pipeline is complete. Now we will need to deploy our Lambda function and then test everything out by pushing a small change to the application to kick off the pipeline.","title":"Step 8: Create Notification Rule For The CodePipeline"},{"location":"provisioning-manual/#step-9-deploy-the-lambda-function-with-the-sam-cli","text":"From a terminal instance with the SAM CLI installed and configured, execute the following commands: sam build sam deploy --guided --parameter-overrides Realm = <o11y cloud realm> AccessToken = <o11y cloud access token>","title":"Step 9: Deploy the Lambda function with the SAM CLI"},{"location":"provisioning-manual/#step-10-push-a-small-change-to-the-source-application-code-to-trigger-a-pipeline-execution","text":"Any change to the source code in the repository will trigger a change. You can even just edit the README.md file in the root of the project. It's nice to show an acutal change to the application, so maybe editing the welcome message that's presented to users on the landing page of the web app is something we want to do. It's easy to make the change, simply open the file located at src/main/resources/messages/messages.properties and edit the welcome message. This text is immediately visible on the landing page and demonstrates that the application code has indeed changed and been deployed to a functional runtime environment. Once you edit the file execute standard git commands to push your change to Github: git add . git commit -m \"Updated the welcome message\" git push","title":"Step 10: Push a small change to the source application code to trigger a pipeline execution"},{"location":"provisioning-manual/#step-11-validate-you-have-custom-events-in-o11y-cloud","text":"Once the pipeline completes successfully, you should be able to search O11y for your custom events. To do so, open up a Dashboard and look for matching events in the Event Overlay field or in the Event Finder panel. Once your events are located you can set them as overlays, create a Table chart showing a list of events, etc...","title":"Step 11: Validate you have custom events in O11y Cloud"}]}